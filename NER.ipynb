{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA2NayPu9l_r"
      },
      "source": [
        "# Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S927Qt_6s3PM"
      },
      "source": [
        "A brief description of the task.\n",
        "Here is the list of all of the current configs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkOFKCKJ9l_x"
      },
      "source": [
        "## Table of contents \n",
        "1. [Models list](#1.-Models-list)\n",
        "\n",
        "2. [Using the model from Python](#2.-Using-the-model-from-Python)\n",
        "\n",
        "    2.1. [Using the pre-trained model for prediction](#1.1-Using-the-pre-trained-model-for-prediction)\n",
        "\n",
        "    2.2. [Train the model on your data](#1.2-Train-the-model-on-your-data) \n",
        "3. [Using the model from the command line](#3.-Using-the-model-from-the-command-line)\n",
        "\n",
        "    3.1. [Using the pre-trained model for prediction](#2.1-Using-the-pre-trained-model-for-prediction)\n",
        "    \n",
        "    3.2. [Train the model on your data](#2.2-Train-the-model-on-your-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luD78iDMs3PP"
      },
      "source": [
        "\n",
        "# 1. Models list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPs3hP2Ms3PR"
      },
      "source": [
        "| Model    | Dataset | Language |\n",
        "| :--- |  | ---: |\n",
        "| `ner_rus_bert_torch <ner/ner_rus_bert_torch.json>`    | Collection3   | Ru |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEYknuKK9l_y"
      },
      "source": [
        "\n",
        "# 2. Using the model from Python "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygOmNC9R9l_y"
      },
      "source": [
        "First make sure you have the DeepPavlov library installed\n",
        "\\#TODO: link to installation page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o-GoKStT9l_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485b44aa-1c78-47a6-807d-5544ff8df478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 880 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 30.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 35.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 16 kB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 23.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 22.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 510 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 19.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 36.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 859 kB 36.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 39.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 654 kB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 42.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 22.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 34.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 219 kB 33.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.0 MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --q deeppavlov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j3tJy1c9l_1"
      },
      "source": [
        "\n",
        "## 1.1 Using the pre-trained model for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLnbUke-9l_3"
      },
      "source": [
        "Build the model using its *config_file* name (in this case - *ner_ontonotes_bert_torch*). \n",
        "\n",
        "What is a config file? # link to the tutorial\n",
        "\n",
        "You can change the NER model you are using by changing the name of the *config_file*.\n",
        "The full list of NER models with their config names can be found **here**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnHw4a6C9l_4"
      },
      "outputs": [],
      "source": [
        "from deeppavlov import configs, build_model\n",
        "\n",
        "ner_model = build_model(configs.ner.ner_ontonotes_bert_torch, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN-BCH1z9l_6"
      },
      "source": [
        "\n",
        "### Predict\n",
        "\n",
        "**input**: list of sequences\n",
        "\n",
        "**output_format**: [list of tokens, list of their corresponding NER-tags]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFXXQf3Q9l_6",
        "outputId": "8089088d-622f-4fd6-cdde-18a3bd2e4f49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
              "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
              " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
              "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLeAxnlu9l_7"
      },
      "source": [
        "\n",
        "## 1.2 Train the model on your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo9slD6v9l_7"
      },
      "source": [
        "\n",
        "### Provide your data path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4aceh89l_8"
      },
      "source": [
        "To train the model on your data, you need to change the path to the training data in the *config_file*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BC6SQW-9l_8"
      },
      "source": [
        "You can do that manually by editing the config json-file.\n",
        "Alternatively, you can parse the *config_file* and change the path to your data from Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcAH6pn79l_8",
        "outputId": "735b026a-88e7-4c17-8e8b-15a4ed7fb9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~/.deeppavlov/downloads/ontonotes/\n"
          ]
        }
      ],
      "source": [
        "from deeppavlov import configs, train_model\n",
        "from deeppavlov.core.commands.utils import parse_config\n",
        "\n",
        "model_config = parse_config(configs.ner.ner_ontonotes_bert_torch)\n",
        "\n",
        "#  dataset that the model was trained on\n",
        "print(model_config['dataset_reader']['data_path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCK5fbHM9l_9"
      },
      "source": [
        "You can provide a *data_path* to your dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QkqD3RJi9l_-"
      },
      "outputs": [],
      "source": [
        "model_config[\"dataset_reader\"][\"data_path\"] = \"/content/faq.csv\"\n",
        "# model_config[\"dataset_reader\"][\"data_url\"] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3OEZVUW9l_-"
      },
      "source": [
        "...or give a link to your data in the *data_url* parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HL5HEEUU9l_-"
      },
      "outputs": [],
      "source": [
        "model_config[\"dataset_reader\"][\"data_path\"] = ''\n",
        "# model_config[\"dataset_reader\"][\"data_url\"] = \"http://files.deeppavlov.ai/faq/school/faq_school_en.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK7yYFFe9l__"
      },
      "source": [
        "\n",
        "### Training dataset format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qz4SMl9l__"
      },
      "source": [
        "To train the neural network, you need to have a dataset in the following format:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOVeJliM9l__"
      },
      "source": [
        "```\n",
        "EU B-ORG\n",
        "rejects O\n",
        "the O\n",
        "call O\n",
        "of O\n",
        "Germany B-LOC\n",
        "to O\n",
        "boycott O\n",
        "lamb O\n",
        "from O\n",
        "Great B-LOC\n",
        "Britain I-LOC\n",
        ". O\n",
        "\n",
        "China B-LOC\n",
        "says O\n",
        "time O\n",
        "right O\n",
        "for O\n",
        "Taiwan B-LOC\n",
        "talks O\n",
        ". O\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhubTsRJ9mAA"
      },
      "source": [
        "The source text is **tokenized** and **tagged**. For each token, there is a tag with BIO markup. Tags are separated from tokens with **whitespaces**. Sentences are separated with **empty lines**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3d_qHA99mAA"
      },
      "source": [
        "??? - Dataset is a text file or a set of text files. The dataset must be split into three parts: train, test, and validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmwcjgld9mAA"
      },
      "source": [
        "\n",
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ETDV4J99mAA"
      },
      "outputs": [],
      "source": [
        "ner_model = train_model(model_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUIG-3q-BqeS"
      },
      "source": [
        "Use your model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDTk4ascBpuI",
        "outputId": "98d57a71-2dd8-4fa1-b8eb-13ddaaad7e15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
              "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
              " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
              "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zgEMO8f9mAA"
      },
      "source": [
        "\n",
        "# 3. Using the model from the command line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGRnpmML9l_2"
      },
      "source": [
        "Before using the model make sure that all required packages are installed using the command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a0ZIHSE9l_3"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov install ner_ontonotes_bert_torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6o9jRPuC6MP"
      },
      "source": [
        "\n",
        "## 2.1 Use the pre-trained model for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV6T8ahx9mAB"
      },
      "outputs": [],
      "source": [
        "!python deeppavlov interact ner_ontonotes_bert_torch [-d]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKoWBEHgC7XM"
      },
      "source": [
        "\n",
        "## 2.2 Train the model on your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Zp3SXvDS6_"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov train ner_ontonotes_bert_torch"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NER.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (doc_env)",
      "language": "python",
      "name": "doc_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}