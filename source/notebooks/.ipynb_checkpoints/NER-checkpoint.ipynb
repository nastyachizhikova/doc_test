{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA2NayPu9l_r"
   },
   "source": [
    "#### Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nastyachizhikova/doc_test/blob/main/source/notebooks/NER.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkOFKCKJ9l_x"
   },
   "source": [
    "# Table of contents \n",
    "\n",
    "1. [Introduction to the task](#1.-Introduction-to-the-task)\n",
    "\n",
    "2. [Get started with the model](#2.-Get-started-with-the-model)\n",
    "\n",
    "3. [Use the model for prediction](#3.-Use-the-model-for-prediction)\n",
    "\n",
    "    3.1. [Predict using Python](#3.1-Predict-using-Python)\n",
    "    \n",
    "    3.2. [Predict using Python pipeline](#3.2-Predict-using-Python-pipeline)\n",
    "    \n",
    "    3.3. [Predict using CLI](#3.3-Predict-using-CLI)\n",
    "     \n",
    "4. [Train the model on your data](#4.-Train-the-model-on-your-data)\n",
    "    \n",
    "    4.1. [Train your model from Python](#4.1-Train-your-model-from-Python)\n",
    "    \n",
    "    4.2. [Train your model from CLI](#4.2-Train-your-model-from-CLI)\n",
    "    \n",
    "5. [Models list](#5.-Models-list)\n",
    "\n",
    "6. [NER-tags list](#6.-NER-tags-list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Named Entity Recognition (NER)** is a task of assigning a tag (from a predefined set of tags) to each token in a given sequence. In other words, NER-task consists of identifying named entities in the text and classifying them into types (e.g. person name, organization, location etc). \n",
    "\n",
    "**BIO encoding schema** is usually used in NER task. It uses 3 tags: B for the beginning of the entity, I for the inside of the entity, and O for non-entity tokens. The second part of the tag stands for the entity type.\n",
    "\n",
    "Here is an example of a tagged sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Elon | Musk | founded | Tesla| in | 2003 | . |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| B-PER | I-PER | O | B-ORG | O | B-DATE | O |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see three extracted named entities: *Elon Musk* (which is a person's name), *Tesla* (which is a name of an organization) and *2003* (which is a date). To see more examples try out our [Demo](https://demo.deeppavlov.ai/#/en/ner)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of possible types of NER entities may vary depending on your dataset domain. The list of tags used in DeepPavlov's models can be found in the [table](#5.-NER-tags-list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get started with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygOmNC9R9l_y"
   },
   "source": [
    "First make sure you have the DeepPavlov Library installed.\n",
    "[More info about the first installation](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Get%20Started%20with%20DeepPavlov.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o-GoKStT9l_z"
   },
   "outputs": [],
   "source": [
    "!pip install --q deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure that all the required packages for the model are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov install ner_ontonotes_bert_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ner_ontonotes_bert_torch` here is the name of the model's *config_file*. [What is a Config File?](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Config%20File.html) \n",
    "\n",
    "Configuration file defines the model and describes its hyperparameters. To use another model, change the name of the *config_file* here and further.\n",
    "The full list of NER models with their config names can be found in the [table](#4.-Models-list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEYknuKK9l_y"
   },
   "source": [
    "\n",
    "# 3. Use the model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j3tJy1c9l_1"
   },
   "source": [
    "## 3.1 Predict using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLnbUke-9l_3"
   },
   "source": [
    "After [installing](#2.-Get-started-with-the-model) the model, build it from the config and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnHw4a6C9l_4"
   },
   "outputs": [],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "ner_model = build_model(configs.ner.ner_ontonotes_bert_torch, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFXXQf3Q9l_6",
    "outputId": "a6087769-fafc-4821-8254-465bc98b9886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict using Python pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use a Python way to describe and build your model for prediction, without using the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from deeppavlov import Element, Model\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "from deeppavlov.download import download_resource\n",
    "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersNerPreprocessor\n",
    "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger\n",
    "\n",
    "\n",
    "transformer = \"bert-base-cased\"\n",
    "model_path = Path('./ner_ontonotes_bert_torch/' + transformer)\n",
    "\n",
    "download_resource(\n",
    "    'http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_torch.tar.gz',\n",
    "    {'./ner_ontonotes_bert_torch'}\n",
    ")\n",
    "\n",
    "preprocessor = TorchTransformersNerPreprocessor(\n",
    "    vocab_file=transformer,\n",
    "    do_lower_case=False,\n",
    "    max_seq_length=512,\n",
    "    max_subword_length=15,\n",
    "    token_masking_prob=0.0,\n",
    ")\n",
    " \n",
    "classes_vocab = SimpleVocabulary(\n",
    "    save_path=model_path/'tag.dict',\n",
    "    load_path=model_path/'tag.dict',\n",
    "    pad_with_zeros=True,\n",
    "    unk_token=[\"O\"]\n",
    ")\n",
    "\n",
    "tagger = TorchTransformersSequenceTagger(\n",
    "    n_tags=classes_vocab.len,\n",
    "    return_probas=False,\n",
    "    use_crf=True,\n",
    "    attention_probs_keep_prob=0.5,\n",
    "    encoder_layer_ids=[-1],\n",
    "    pretrained_bert='bert-base-cased',\n",
    "    save_path=model_path/'model',\n",
    "    load_path=model_path/'model',\n",
    "    optimizer='AdamW',\n",
    "    optimizer_parameters={'lr': 2e-05, \n",
    "                          \"weight_decay\": 1e-06, \n",
    "                          \"betas\": [0.9, 0.999],\n",
    "                          \"eps\": 1e-06},\n",
    "    clip_norm=1.0,\n",
    "    min_learning_rate=1e-07,\n",
    "    learning_rate_drop_patience=30,\n",
    "    learning_rate_drop_div=1.5,\n",
    "    load_before_drop=True,\n",
    ")\n",
    "\n",
    "ner_model = Model(\n",
    "    x=['x'],\n",
    "    out=[\"x_tokens\", \"y_pred\"],\n",
    "    pipe=[\n",
    "        Element(component=preprocessor, x=['x'], out=[\"x_tokens\", \"x_subword_tokens\", \"x_subword_tok_ids\", \"startofword_markers\", \"attention_mask\"]),\n",
    "        Element(component=classes_vocab, x=[\"y\"], out=[\"y_ind\"]),\n",
    "        Element(component=tagger, x=[\"x_subword_tok_ids\", \"attention_mask\", \"startofword_markers\"], out=[\"y_pred_ind\"]),\n",
    "        Element(component=classes_vocab, x=[\"y_pred_ind\"], out=[\"y_pred\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFXXQf3Q9l_6",
    "outputId": "a6087769-fafc-4821-8254-465bc98b9886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLeAxnlu9l_7"
   },
   "source": [
    "## 3.3 Predict using CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get predictions in an interactive mode through CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python deeppavlov interact ner_ontonotes_bert_torch [-d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-d` is an optional download key (alternative to `download=True` in Python code). The key `-d` is used to download the pre-trained model along with embeddings and all other files needed to run the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or make predictions for samples from *stdin*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python deeppavlov predict ner_ontonotes_bert_torch -f <file-name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the model on your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo9slD6v9l_7"
   },
   "source": [
    "\n",
    "## 4.1 Train your model from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide your data path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T4aceh89l_8"
   },
   "source": [
    "To train the model on your data, you need to change the path to the training data in the *config_file*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BC6SQW-9l_8"
   },
   "source": [
    "Parse the *config_file* and change the path to your data from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcAH6pn79l_8",
    "outputId": "168d496d-453d-4db6-f927-18420f577e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/ontonotes/\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config(configs.ner.ner_ontonotes_bert_torch)\n",
    "\n",
    "#  dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCK5fbHM9l_9"
   },
   "source": [
    "Provide a *data_path* to your own dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip a new example dataset\n",
    "!wget http://files.deeppavlov.ai/deeppavlov_data/conll2003_v2.tar.gz\n",
    "!tar -xzvf \"conll2003_v2.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QkqD3RJi9l_-"
   },
   "outputs": [],
   "source": [
    "# provide a path to the train file\n",
    "model_config[\"dataset_reader\"][\"data_path\"] = \"contents/train.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK7yYFFe9l__"
   },
   "source": [
    "\n",
    "### Train dataset format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2qz4SMl9l__"
   },
   "source": [
    "To train the model, you need to have a txt-file with a dataset in the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOVeJliM9l__"
   },
   "source": [
    "```\n",
    "EU B-ORG\n",
    "rejects O\n",
    "the O\n",
    "call O\n",
    "of O\n",
    "Germany B-LOC\n",
    "to O\n",
    "boycott O\n",
    "lamb O\n",
    "from O\n",
    "Great B-LOC\n",
    "Britain I-LOC\n",
    ". O\n",
    "\n",
    "China B-LOC\n",
    "says O\n",
    "time O\n",
    "right O\n",
    "for O\n",
    "Taiwan B-LOC\n",
    "talks O\n",
    ". O\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhubTsRJ9mAA"
   },
   "source": [
    "The source text is **tokenized** and **tagged**. For each token, there is a tag with BIO markup. Tags are separated from tokens with **whitespaces**. Sentences are separated with **empty lines**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmwcjgld9mAA"
   },
   "source": [
    "\n",
    "### Train the model using new config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ETDV4J99mAA"
   },
   "outputs": [],
   "source": [
    "ner_model = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUIG-3q-BqeS"
   },
   "source": [
    "Use your model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDTk4ascBpuI",
    "outputId": "98d57a71-2dd8-4fa1-b8eb-13ddaaad7e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKoWBEHgC7XM"
   },
   "source": [
    "## 4.2 Train your model from CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-Zp3SXvDS6_"
   },
   "outputs": [],
   "source": [
    "! python -m deeppavlov train ner_ontonotes_bert_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table presents a list of all of the NER-models available in DeepPavlov Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Config name  | Dataset | Language | Model Size | F1 score |\n",
    "| :--- | --- | --- | --- | ---: |\n",
    "| [ner_ontonotes_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert.json)\n",
    "[ner_ontonotes_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_probas.json)| Ontonotes   | En | 1.3 GB | 87.9 |\n",
    "| [ner_ontonotes_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_probas.json)|| En | ? | ? |\n",
    "| [ner_ontonotes_bert_mult](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_mult.json)|| Multi | 2.0 GB | 87.2 |\n",
    "| [ner_rus_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert.json)| Collection3   | Ru | 2.0 GB | 97.7 |\n",
    "| [ner_rus_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert_probas.json)| Collection3   | Ru | ? | ? |\n",
    "| [ner_rus_convers_distilrubert_2L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_2L.json)| Collection3   | Ru | ? | ? |\n",
    "| [ner_rus_convers_distilrubert_6L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_6L.json)| Collection3   | Ru |? | ? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. NER-tags list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table presents a list of all of the NER entity tags used in DeepPavlov's NER-models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              |                                                        |\n",
    "| ------------ | ------------------------------------------------------ |\n",
    "| **PERSON**       | People including fictional                             |\n",
    "| **NORP**         | Nationalities or religious or political groups         |\n",
    "| **FACILITY**     | Buildings, airports, highways, bridges, etc.           |\n",
    "| **ORGANIZATION** | Companies, agencies, institutions, etc.                |\n",
    "| **GPE**          | Countries, cities, states                              |\n",
    "| **LOCATION**     | Non-GPE locations, mountain ranges, bodies of water    |\n",
    "| **PRODUCT**      | Vehicles, weapons, foods, etc. (Not services)          |\n",
    "| **EVENT**        | Named hurricanes, battles, wars, sports events, etc.   |\n",
    "| **WORK OF ART**  | Titles of books, songs, etc.                           |\n",
    "| **LAW**          | Named documents made into laws                         |\n",
    "| **LANGUAGE**     | Any named language                                     |\n",
    "| **DATE**         | Absolute or relative dates or periods                  |\n",
    "| **TIME**         | Times smaller than a day                               |\n",
    "| **PERCENT**      | Percentage (including “%”)                             |\n",
    "| **MONEY**        | Monetary values, including unit                        |\n",
    "| **QUANTITY**     | Measurements, as of weight or distance                 |\n",
    "| **ORDINAL**      | “first”, “second”                                      |\n",
    "| **CARDINAL**     | Numerals that do not fall under another type           |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
