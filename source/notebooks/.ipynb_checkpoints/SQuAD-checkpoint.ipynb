{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wA2NayPu9l_r"
   },
   "source": [
    "#### Context Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nastyachizhikova/doc_test/blob/main/source/notebooks/NER.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkOFKCKJ9l_x"
   },
   "source": [
    "# Table of contents \n",
    "\n",
    "1. [Introduction to the task](#1.-Introduction-to-the-task)\n",
    "\n",
    "2. [Get started with the model](#2.-Get-started-with-the-model)\n",
    "\n",
    "3. [Use the model for prediction](#3.-Use-the-model-for-prediction)\n",
    "\n",
    "    3.1. [Predict using Python](#3.1-Predict-using-Python)\n",
    "    \n",
    "    3.2. [Predict using Python pipeline](#3.2-Predict-using-Python-pipeline)\n",
    "    \n",
    "    3.3. [Predict using CLI](#3.3-Predict-using-CLI)\n",
    "     \n",
    "4. [Train the model on your data](#4.-Train-the-model-on-your-data)\n",
    "    \n",
    "    4.1. [Train your model from Python](#4.1-Train-your-model-from-Python)\n",
    "    \n",
    "    4.2. [Train your model from CLI](#4.2-Train-your-model-from-CLI)\n",
    "    \n",
    "5. [Models list](#5.-Models-list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Question Answering is a task of finding a fragment with an answer to a question in a given segment of context.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Context | Question | Answer |\n",
    "| --- | --- | --- |\n",
    "| In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals **within a cloud**. Short, intense periods of rain in scattered locations are called “showers”. | Where do water droplets collide with ice crystals to form precipitation? | within a cloud |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see how the answer to the question 'Where do water droplets collide with ice crystals to form precipitation?' can be extracted from the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets that follow this task format:\n",
    "\n",
    "- Stanford Question Answering Dataset (SQuAD) (EN)\n",
    "\n",
    "- SDSJ Task B (RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get started with the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygOmNC9R9l_y"
   },
   "source": [
    "First make sure you have the DeepPavlov Library installed.\n",
    "[More info about the first installation](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Get%20Started%20with%20DeepPavlov.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o-GoKStT9l_z"
   },
   "outputs": [],
   "source": [
    "!pip install --q deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure that all the required packages for the model are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov install squad_ru_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`squad_ru_bert` here is the name of the model's *config_file*. [What is a Config File?](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Config%20File.html) \n",
    "\n",
    "Configuration file defines the model and describes its hyperparameters. To use another model, change the name of the *config_file* here and further.\n",
    "The full list of NER models with their config names can be found in the [table](#4.-Models-list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEYknuKK9l_y"
   },
   "source": [
    "\n",
    "# 3. Use the model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j3tJy1c9l_1"
   },
   "source": [
    "## 3.1 Predict using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLnbUke-9l_3"
   },
   "source": [
    "After [installing](#2.-Get-started-with-the-model) the model, build it from the config and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnHw4a6C9l_4"
   },
   "outputs": [],
   "source": [
    "from deeppavlov import configs, build_model\n",
    "\n",
    "model = build_model(configs.squad.squad_ru_bert, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**: List with the context, list with the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFXXQf3Q9l_6",
    "outputId": "a6087769-fafc-4821-8254-465bc98b9886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['DeepPavlov is library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict using Python pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use a Python way to describe and build your model for prediction, without using the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from deeppavlov import Element, Model\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "from deeppavlov.download import download_resource\n",
    "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersNerPreprocessor\n",
    "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger\n",
    "\n",
    "\n",
    "transformer = \"bert-base-cased\"\n",
    "model_path = Path('./squad_ru_bert/' + transformer)\n",
    "\n",
    "download_resource(\n",
    "    'http://files.deeppavlov.ai/v1/squad/ner_ontonotes_bert_torch.tar.gz',\n",
    "    {'./ner_ontonotes_bert_torch'}\n",
    ")\n",
    "\n",
    "preprocessor = TorchTransformersNerPreprocessor(\n",
    "    vocab_file=transformer,\n",
    "    do_lower_case=False,\n",
    "    max_seq_length=512,\n",
    "    max_subword_length=15,\n",
    "    token_masking_prob=0.0,\n",
    ")\n",
    " \n",
    "classes_vocab = SimpleVocabulary(\n",
    "    save_path=model_path/'tag.dict',\n",
    "    load_path=model_path/'tag.dict',\n",
    "    pad_with_zeros=True,\n",
    "    unk_token=[\"O\"]\n",
    ")\n",
    "\n",
    "tagger = TorchTransformersSequenceTagger(\n",
    "    n_tags=classes_vocab.len,\n",
    "    return_probas=False,\n",
    "    use_crf=True,\n",
    "    attention_probs_keep_prob=0.5,\n",
    "    encoder_layer_ids=[-1],\n",
    "    pretrained_bert='bert-base-cased',\n",
    "    save_path=model_path/'model',\n",
    "    load_path=model_path/'model',\n",
    "    optimizer='AdamW',\n",
    "    optimizer_parameters={'lr': 2e-05, \n",
    "                          \"weight_decay\": 1e-06, \n",
    "                          \"betas\": [0.9, 0.999],\n",
    "                          \"eps\": 1e-06},\n",
    "    clip_norm=1.0,\n",
    "    min_learning_rate=1e-07,\n",
    "    learning_rate_drop_patience=30,\n",
    "    learning_rate_drop_div=1.5,\n",
    "    load_before_drop=True,\n",
    ")\n",
    "\n",
    "ner_model = Model(\n",
    "    x=['x'],\n",
    "    out=[\"x_tokens\", \"y_pred\"],\n",
    "    pipe=[\n",
    "        Element(component=preprocessor, x=['x'], out=[\"x_tokens\", \"x_subword_tokens\", \"x_subword_tok_ids\", \"startofword_markers\", \"attention_mask\"]),\n",
    "        Element(component=classes_vocab, x=[\"y\"], out=[\"y_ind\"]),\n",
    "        Element(component=tagger, x=[\"x_subword_tok_ids\", \"attention_mask\", \"startofword_markers\"], out=[\"y_pred_ind\"]),\n",
    "        Element(component=classes_vocab, x=[\"y_pred_ind\"], out=[\"y_pred\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFXXQf3Q9l_6",
    "outputId": "a6087769-fafc-4821-8254-465bc98b9886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLeAxnlu9l_7"
   },
   "source": [
    "## 3.3 Predict using CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get predictions in an interactive mode through CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python deeppavlov interact squad_ru_bert [-d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-d` is an optional download key (alternative to `download=True` in Python code). The key `-d` is used to download the pre-trained model along with embeddings and all other files needed to run the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or make predictions for samples from *stdin*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python deeppavlov predict squad_ru_bert -f <file-name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the model on your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo9slD6v9l_7"
   },
   "source": [
    "\n",
    "## 4.1 Train your model from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide your data path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T4aceh89l_8"
   },
   "source": [
    "To train the model on your data, you need to change the path to the training data in the *config_file*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BC6SQW-9l_8"
   },
   "source": [
    "Parse the *config_file* and change the path to your data from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcAH6pn79l_8",
    "outputId": "168d496d-453d-4db6-f927-18420f577e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/ontonotes/\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import configs, train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config(configs.squad.squad_ru_bert)\n",
    "\n",
    "#  dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCK5fbHM9l_9"
   },
   "source": [
    "Provide a *data_path* to your own dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip a new example dataset\n",
    "!wget http://files.deeppavlov.ai/deeppavlov_data/conll2003_v2.tar.gz\n",
    "!tar -xzvf \"conll2003_v2.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QkqD3RJi9l_-"
   },
   "outputs": [],
   "source": [
    "# provide a path to the train file\n",
    "model_config[\"dataset_reader\"][\"data_path\"] = \"contents/train.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK7yYFFe9l__"
   },
   "source": [
    "\n",
    "### Train dataset format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2qz4SMl9l__"
   },
   "source": [
    "To train the model, you need to have a txt-file with a dataset in the following format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhubTsRJ9mAA"
   },
   "source": [
    "The source text is **tokenized** and **tagged**. For each token, there is a tag with BIO markup. Tags are separated from tokens with **whitespaces**. Sentences are separated with **empty lines**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmwcjgld9mAA"
   },
   "source": [
    "\n",
    "### Train the model using new config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ETDV4J99mAA"
   },
   "outputs": [],
   "source": [
    "ner_model = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUIG-3q-BqeS"
   },
   "source": [
    "Use your model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDTk4ascBpuI",
    "outputId": "98d57a71-2dd8-4fa1-b8eb-13ddaaad7e15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKoWBEHgC7XM"
   },
   "source": [
    "## 4.2 Train your model from CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-Zp3SXvDS6_"
   },
   "outputs": [],
   "source": [
    "! python -m deeppavlov train squad_ru_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table presents a list of all of the NER-models available in DeepPavlov Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Config name  | Dataset | Language | Model Size | F1 score |\n",
    "| :--- | --- | --- | --- | ---: |\n",
    "| [ner_ontonotes_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert.json) | Ontonotes | En | 1.3 GB | 87.9 |\n",
    "| [ner_ontonotes_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_probas.json)| ? | ? |\n",
    "| [ner_ontonotes_bert_mult](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_mult.json)| Ontonotes | Multi | 2.0 GB | 87.2 |\n",
    "| [ner_rus_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert.json)| Collection3   | Ru | 2.0 GB | 97.7 |\n",
    "| [ner_rus_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert_probas.json)| Collection3   | Ru | ? | ? |\n",
    "| [ner_rus_convers_distilrubert_2L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_2L.json)| Collection3   | Ru | ? | ? |\n",
    "| [ner_rus_convers_distilrubert_6L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_6L.json)| Collection3   | Ru |? | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <td>ex 1</td>\n",
    "    <td>ex 2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ex 1</td>\n",
    "    <td>ex 2</td>\n",
    "  </tr>\n",
    "</thead>\n",
    "  <tr>\n",
    "    <td>ex 1</td>\n",
    "    <td>ex 2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
