{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1e850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a76478e",
   "metadata": {},
   "source": [
    "## 3.2 Predict using Python pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9e468",
   "metadata": {},
   "source": [
    "Alternatively, you can use a Python way to describe and build your model for prediction, without using the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cd815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from deeppavlov import Element, Model\n",
    "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
    "from deeppavlov.download import download_resource\n",
    "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersNerPreprocessor\n",
    "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger\n",
    "\n",
    "\n",
    "transformer = \"bert-base-cased\"\n",
    "model_path = Path('./ner_ontonotes_bert_torch/' + transformer)\n",
    "\n",
    "download_resource(\n",
    "    'http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_torch.tar.gz',\n",
    "    {'./ner_ontonotes_bert_torch'}\n",
    ")\n",
    "\n",
    "preprocessor = TorchTransformersNerPreprocessor(\n",
    "    vocab_file=transformer,\n",
    "    do_lower_case=False,\n",
    "    max_seq_length=512,\n",
    "    max_subword_length=15,\n",
    "    token_masking_prob=0.0,\n",
    ")\n",
    " \n",
    "classes_vocab = SimpleVocabulary(\n",
    "    save_path=model_path/'tag.dict',\n",
    "    load_path=model_path/'tag.dict',\n",
    "    pad_with_zeros=True,\n",
    "    unk_token=[\"O\"]\n",
    ")\n",
    "\n",
    "tagger = TorchTransformersSequenceTagger(\n",
    "    n_tags=classes_vocab.len,\n",
    "    return_probas=False,\n",
    "    use_crf=True,\n",
    "    attention_probs_keep_prob=0.5,\n",
    "    encoder_layer_ids=[-1],\n",
    "    pretrained_bert='bert-base-cased',\n",
    "    save_path=model_path/'model',\n",
    "    load_path=model_path/'model',\n",
    "    optimizer='AdamW',\n",
    "    optimizer_parameters={'lr': 2e-05, \n",
    "                          \"weight_decay\": 1e-06, \n",
    "                          \"betas\": [0.9, 0.999],\n",
    "                          \"eps\": 1e-06},\n",
    "    clip_norm=1.0,\n",
    "    min_learning_rate=1e-07,\n",
    "    learning_rate_drop_patience=30,\n",
    "    learning_rate_drop_div=1.5,\n",
    "    load_before_drop=True,\n",
    ")\n",
    "\n",
    "ner_model = Model(\n",
    "    x=['x'],\n",
    "    out=[\"x_tokens\", \"y_pred\"],\n",
    "    pipe=[\n",
    "        Element(component=preprocessor, \n",
    "                x=['x'], \n",
    "                out=[\"x_tokens\", \"x_subword_tokens\", \"x_subword_tok_ids\", \"startofword_markers\", \"attention_mask\"]),\n",
    "        \n",
    "        Element(component=classes_vocab, \n",
    "                x=[\"y\"], \n",
    "                out=[\"y_ind\"]),\n",
    "        \n",
    "        Element(component=tagger, \n",
    "                x=[\"x_subword_tok_ids\", \"attention_mask\", \"startofword_markers\"], \n",
    "                out=[\"y_pred_ind\"]),\n",
    "        \n",
    "        Element(component=classes_vocab, \n",
    "                x=[\"y_pred_ind\"], \n",
    "                out=[\"y_pred\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cac10c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFXXQf3Q9l_6",
    "outputId": "a6087769-fafc-4821-8254-465bc98b9886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Bob', 'Ross', 'lived', 'in', 'Florida'],\n",
       "  ['Elon', 'Musk', 'founded', 'Tesla']],\n",
       " [['B-PERSON', 'I-PERSON', 'O', 'O', 'B-GPE'],\n",
       "  ['B-PERSON', 'I-PERSON', 'O', 'B-ORG']]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['Bob Ross lived in Florida', 'Elon Musk founded Tesla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcaef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ed8f51",
   "metadata": {
    "id": "eo4EWaTWpBpr"
   },
   "source": [
    "## 3.2 Predict using Python pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ddafd",
   "metadata": {
    "id": "w7dqzRxzpBpr"
   },
   "source": [
    "Alternatively, you can use a Python way to describe and build your model for prediction, without using the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632f96f",
   "metadata": {
    "id": "jm4__pF7pBpr"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from deeppavlov import Element, Model\n",
    "from deeppavlov.download import download_resource\n",
    "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchSquadTransformersPreprocessor\n",
    "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger\n",
    "from deeppavlov.models.preprocessors.squad_preprocessor import SquadBertAnsPreprocessor, SquadBertMappingPreprocessor, SquadBertAnsPostprocessor\n",
    "from deeppavlov.models.torch_bert.torch_transformers_squad import TorchTransformersSquad\n",
    "\n",
    "\n",
    "transformer = 'bert-base-uncased'\n",
    "model_path = Path('./squad_torch_bert')\n",
    "lowercase = True \n",
    "\n",
    "download_resource(\n",
    "    'http://files.deeppavlov.ai/v1/squad/squad_torch_bert.tar.gz',\n",
    "    {'./squad_torch_bert'}\n",
    ")\n",
    "\n",
    "in_preprocessor = TorchSquadTransformersPreprocessor(\n",
    "    vocab_file=transformer,\n",
    "    do_lower_case=lowercase,\n",
    "    max_seq_length=384,\n",
    "    return_tokens=True\n",
    ")\n",
    " \n",
    "mapping = SquadBertMappingPreprocessor(\n",
    "    do_lower_case=lowercase\n",
    ")\n",
    "\n",
    "transformer = TorchTransformersSquad(\n",
    "    pretrained_bert=transformer,\n",
    "    save_path=model_path/'model',\n",
    "    load_path=model_path/'model',\n",
    "    optimizer='AdamW',\n",
    "    optimizer_parameters={\n",
    "        'lr': 2e-05,\n",
    "        'weight_decay': 0.01,\n",
    "        'betas': [\n",
    "            0.9,\n",
    "            0.999\n",
    "        ],\n",
    "        'eps': 1e-06\n",
    "    },\n",
    "    learning_rate_drop_patience=2,\n",
    "    learning_rate_drop_div=2.0,\n",
    ")\n",
    "\n",
    "ans_postprocessor = SquadBertAnsPostprocessor()\n",
    "\n",
    "model = Model(\n",
    "    x=['context_raw', 'question_raw'],\n",
    "    out=['ans_predicted', 'ans_start_predicted',\n",
    "      \"logits\"],\n",
    "    pipe=[\n",
    "        Element(component=in_preprocessor, \n",
    "                x=['context_raw', 'question_raw'], \n",
    "                out=['bert_features', 'subtokens']),\n",
    "          \n",
    "        Element(component=mapping, \n",
    "                x=['context_raw', 'bert_features', 'subtokens'], \n",
    "                out=['subtok2chars', 'char2subtoks']),\n",
    "          \n",
    "        Element(component=transformer, \n",
    "                x=['bert_features'], \n",
    "                out=['ans_start_predicted', 'ans_end_predicted', 'logits']),\n",
    "        \n",
    "        Element(component=ans_postprocessor, \n",
    "                x=['ans_start_predicted', 'ans_end_predicted', 'context_raw', 'bert_features', 'subtok2chars', 'subtokens'], \n",
    "                out=['ans_predicted', 'ans_start_predicted', 'ans_end_predicted'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07b6c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xy9zN5JrnNwz",
    "outputId": "5d52e258-f0d8-4b5f-82c1-b136ec313bb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['library for NLP and dialog systems'], [14], [348392.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['DeepPavlov is library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
