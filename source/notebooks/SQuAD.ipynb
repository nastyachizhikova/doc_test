{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA2NayPu9l_r"
      },
      "source": [
        "#### Context Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUXb756_pBpb"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nastyachizhikova/doc_test/blob/main/source/notebooks/squad.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkOFKCKJ9l_x"
      },
      "source": [
        "# Table of contents \n",
        "\n",
        "1. [Introduction to the task](#1.-Introduction-to-the-task)\n",
        "\n",
        "2. [Get started with the model](#2.-Get-started-with-the-model)\n",
        "\n",
        "3. [Use the model for prediction](#3.-Use-the-model-for-prediction)\n",
        "\n",
        "    3.1. [Predict using Python](#3.1-Predict-using-Python)\n",
        "    \n",
        "    3.2. [Predict using Python pipeline](#3.2-Predict-using-Python-pipeline)\n",
        "    \n",
        "    3.3. [Predict using CLI](#3.3-Predict-using-CLI)\n",
        "     \n",
        "4. [Train the model on your data](#4.-Train-the-model-on-your-data)\n",
        "    \n",
        "    4.1. [Train your model from Python](#4.1-Train-your-model-from-Python)\n",
        "    \n",
        "    4.2. [Train your model from CLI](#4.2-Train-your-model-from-CLI)\n",
        "    \n",
        "5. [Models list](#5.-Models-list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rlEvcLSpBpe"
      },
      "source": [
        "# 1. Introduction to the task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HDPkc-pBpe"
      },
      "source": [
        "Context Question Answering is a task of finding a fragment with an answer to a question in a given segment of context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP5cV4AZ_FOf"
      },
      "source": [
        "**Context**:\n",
        "\n",
        "In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals **within a cloud**. Short, intense periods of rain in scattered locations are called “showers”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtJfjLT3pBpf"
      },
      "source": [
        "**Question**:\n",
        "Where do water droplets collide with ice crystals to form precipitation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrx2O8En_FOh"
      },
      "source": [
        "**Answer**: within a cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEjlhWiNpBpi"
      },
      "source": [
        "Datasets that follow this task format:\n",
        "\n",
        "- [Stanford Question Answering Dataset (SQuAD) (EN)](https://rajpurkar.github.io/SQuAD-explorer/)\n",
        "\n",
        "- [SberQuAD (RU)](https://paperswithcode.com/dataset/sberquad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uukjNH87Syaf"
      },
      "source": [
        "To learn more about Context Question Answering application, read [our article](https://medium.com/deeppavlov/developing-qa-systems-for-any-language-with-deeppavlov-a9033d5231a8) on Medium. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzHeUOeqpBpk"
      },
      "source": [
        "# 2. Get started with the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygOmNC9R9l_y"
      },
      "source": [
        "First make sure you have the DeepPavlov Library installed.\n",
        "[More info about the first installation](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Get%20Started%20with%20DeepPavlov.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-GoKStT9l_z"
      },
      "outputs": [],
      "source": [
        "!pip install --q deeppavlov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTBqvEtdpBpm"
      },
      "source": [
        "Then make sure that all the required packages for the model are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYx-1sDqpBpn"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov install squad_torch_bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6hPLgzvpBpn"
      },
      "source": [
        "`squad_torch_bert` here is the name of the model's *config_file*. [What is a Config File?](https://deeppavlov-test.readthedocs.io/en/latest/notebooks/Config%20File.html) \n",
        "\n",
        "Configuration file defines the model and describes its hyperparameters. To use another model, change the name of the *config_file* here and further.\n",
        "The full list of the models with their config names can be found in the [table](#4.-Models-list)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEYknuKK9l_y"
      },
      "source": [
        "\n",
        "# 3. Use the model for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j3tJy1c9l_1"
      },
      "source": [
        "## 3.1 Predict using Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLnbUke-9l_3"
      },
      "source": [
        "After [installing](#2.-Get-started-with-the-model) the model, build it from the config and predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnHw4a6C9l_4"
      },
      "outputs": [],
      "source": [
        "from deeppavlov import configs, build_model\n",
        "\n",
        "model = build_model(configs.squad.squad_torch_bert, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec572M3jpBpp"
      },
      "source": [
        "**Input**: List[context, question]\n",
        "\n",
        "**Output**: List[answer, start_character, logit]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFXXQf3Q9l_6",
        "outputId": "8eacb57f-c5c5-4d6c-a155-8999917f7506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a library for NLP and dialog systems'], [14], [200928.390625]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model(['DeepPavlov is a library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo4EWaTWpBpr"
      },
      "source": [
        "## 3.2 Predict using Python pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7dqzRxzpBpr"
      },
      "source": [
        "Alternatively, you can use a Python way to describe and build your model for prediction, without using the config file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm4__pF7pBpr"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from deeppavlov import Element, Model\n",
        "from deeppavlov.download import download_resource\n",
        "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchSquadTransformersPreprocessor\n",
        "from deeppavlov.models.torch_bert.torch_transformers_sequence_tagger import TorchTransformersSequenceTagger\n",
        "from deeppavlov.models.preprocessors.squad_preprocessor import SquadBertAnsPreprocessor, SquadBertMappingPreprocessor, SquadBertAnsPostprocessor\n",
        "from deeppavlov.models.torch_bert.torch_transformers_squad import TorchTransformersSquad\n",
        "\n",
        "\n",
        "transformer = 'bert-base-uncased'\n",
        "model_path = Path('./squad_torch_bert')\n",
        "lowercase = True \n",
        "\n",
        "download_resource(\n",
        "    'http://files.deeppavlov.ai/v1/squad/squad_torch_bert.tar.gz',\n",
        "    {'./squad_torch_bert'}\n",
        ")\n",
        "\n",
        "in_preprocessor = TorchSquadTransformersPreprocessor(\n",
        "    vocab_file=transformer,\n",
        "    do_lower_case=lowercase,\n",
        "    max_seq_length=384,\n",
        "    return_tokens=True\n",
        ")\n",
        " \n",
        "mapping = SquadBertMappingPreprocessor(\n",
        "    do_lower_case=lowercase\n",
        ")\n",
        "\n",
        "transformer = TorchTransformersSquad(\n",
        "    pretrained_bert=transformer,\n",
        "    save_path=model_path/'model',\n",
        "    load_path=model_path/'model',\n",
        "    optimizer='AdamW',\n",
        "    optimizer_parameters={\n",
        "        'lr': 2e-05,\n",
        "        'weight_decay': 0.01,\n",
        "        'betas': [\n",
        "            0.9,\n",
        "            0.999\n",
        "        ],\n",
        "        'eps': 1e-06\n",
        "    },\n",
        "    learning_rate_drop_patience=2,\n",
        "    learning_rate_drop_div=2.0,\n",
        ")\n",
        "\n",
        "ans_postprocessor = SquadBertAnsPostprocessor()\n",
        "\n",
        "model = Model(\n",
        "    x=['context_raw', 'question_raw'],\n",
        "    out=['ans_predicted', 'ans_start_predicted',\n",
        "      \"logits\"],\n",
        "    pipe=[\n",
        "        Element(component=in_preprocessor, \n",
        "                x=['context_raw', 'question_raw'], \n",
        "                out=['bert_features', 'subtokens']),\n",
        "          \n",
        "        Element(component=mapping, \n",
        "                x=['context_raw', 'bert_features', 'subtokens'], \n",
        "                out=['subtok2chars', 'char2subtoks']),\n",
        "          \n",
        "        Element(component=transformer, \n",
        "                x=['bert_features'], \n",
        "                out=['ans_start_predicted', 'ans_end_predicted', 'logits']),\n",
        "        \n",
        "        Element(component=ans_postprocessor, \n",
        "                x=['ans_start_predicted', 'ans_end_predicted', 'context_raw', 'bert_features', 'subtok2chars', 'subtokens'], \n",
        "                out=['ans_predicted', 'ans_start_predicted', 'ans_end_predicted'])\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eacb57f-c5c5-4d6c-a155-8999917f7506",
        "id": "wf7UkJxfBROB"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a library for NLP and dialog systems'], [14], [200928.390625]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model(['DeepPavlov is a library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLeAxnlu9l_7"
      },
      "source": [
        "## 3.3 Predict using CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE3j768spBps"
      },
      "source": [
        "You can also get predictions in an interactive mode through CLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG8DoLyCtue7"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov interact squad_torch_bert -d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOga6p9KpBps"
      },
      "source": [
        "`-d` is an optional download key (alternative to `download=True` in Python code). The key `-d` is used to download the pre-trained model along with embeddings and all other files needed to run the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0I_vIirpBpt"
      },
      "source": [
        "Or make predictions for samples from *stdin*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOUND8frpBpt"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov predict squad_torch_bert -f <file-name>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMynAl4OpBpt"
      },
      "source": [
        "# 4. Train the model on your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo9slD6v9l_7"
      },
      "source": [
        "\n",
        "## 4.1 Train your model from Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhE1rF4fpBpt"
      },
      "source": [
        "### Provide your data path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4aceh89l_8"
      },
      "source": [
        "To train the model on your data, you need to change the path to the training data in the *config_file*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BC6SQW-9l_8"
      },
      "source": [
        "Parse the *config_file* and change the path to your data from Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcAH6pn79l_8",
        "outputId": "c0573246-63e6-4246-c618-5ac1d901314b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "~/.deeppavlov/downloads/squad/\n"
          ]
        }
      ],
      "source": [
        "from deeppavlov import configs, train_model\n",
        "from deeppavlov.core.commands.utils import parse_config\n",
        "\n",
        "model_config = parse_config(configs.squad.squad_torch_bert)\n",
        "\n",
        "#  dataset that the model was trained on\n",
        "print(model_config['dataset_reader']['data_path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCK5fbHM9l_9"
      },
      "source": [
        "Provide a *data_path* to your own dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzb2zO5wpBpu"
      },
      "outputs": [],
      "source": [
        "# download and unzip a new example dataset\n",
        "!wget http://files.deeppavlov.ai/datasets/squad-v1.1.tar.gz\n",
        "!tar -xzvf \"squad-v1.1.tar.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL2URAdKq99K"
      },
      "source": [
        "Note that if you want to provide your own dataset, it should have the same format as the SQuAD dataset downloaded in this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkqD3RJi9l_-"
      },
      "outputs": [],
      "source": [
        "# provide a path to the train file\n",
        "model_config[\"dataset_reader\"][\"data_path\"] = \"/contents/train-v1.1.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmwcjgld9mAA"
      },
      "source": [
        "\n",
        "### Train the model using new config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ETDV4J99mAA"
      },
      "outputs": [],
      "source": [
        "model = train_model(model_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUIG-3q-BqeS"
      },
      "source": [
        "Use your model for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eacb57f-c5c5-4d6c-a155-8999917f7506",
        "id": "dynRGNMHBVAl"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a library for NLP and dialog systems'], [14], [200928.390625]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model(['DeepPavlov is a library for NLP and dialog systems.'], ['What is DeepPavlov?'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKoWBEHgC7XM"
      },
      "source": [
        "## 4.2 Train your model from CLI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Zp3SXvDS6_"
      },
      "outputs": [],
      "source": [
        "!python -m deeppavlov train squad_torch_bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csO-hGQvpBpx"
      },
      "source": [
        "# 5. Models list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYftVMtmpBpx"
      },
      "source": [
        "The table presents a list of all of the NER-models available in DeepPavlov Library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QHx_g25pBpy"
      },
      "source": [
        "| Config name  | Dataset | Language | Model Size | F1 score |\n",
        "| :--- | --- | --- | --- | ---: |\n",
        "| [ner_ontonotes_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert.json) | Ontonotes | En | 1.3 GB | 87.9 |\n",
        "| [ner_ontonotes_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_probas.json)| ? | ? |\n",
        "| [ner_ontonotes_bert_mult](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_ontonotes_bert_mult.json)| Ontonotes | Multi | 2.0 GB | 87.2 |\n",
        "| [ner_rus_bert](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert.json)| Collection3   | Ru | 2.0 GB | 97.7 |\n",
        "| [ner_rus_bert_probas](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_bert_probas.json)| Collection3   | Ru | ? | ? |\n",
        "| [ner_rus_convers_distilrubert_2L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_2L.json)| Collection3   | Ru | ? | ? |\n",
        "| [ner_rus_convers_distilrubert_6L](https://github.com/deepmipt/DeepPavlov/blob/dev/deeppavlov/configs/ner/ner_rus_convers_distilrubert_6L.json)| Collection3   | Ru |? | ? |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KAkAH6opBpz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SQuAD.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}